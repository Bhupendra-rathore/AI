# openai embeddings needed




# from langchain_exprimental.text_splitter import SemanticChunker
# from langchain.text_splitter import Language
# from dotenv import load_dotenv

# load_dotenv()

# text="""
# def abd():
#     print("xyz")
# def abc(a):
#     print("abc")

# a=abc(2)
# print(a)
# """


# splitter=SemanticChunker(
#     language=Language.PYTHON,
#     chunk_size=30,
#     chunk_overlap=0


# )

# chunks=splitter.split_text(text)

# print(len(chunks))

# print(chunks)